{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征抽取：**就是逐条将原始数据转化为特征向量的形式，这个过程同时涉及对数据特征的量化表示；而特征筛选则更进一步，在高维度、已向量化的特征向量中选择对指定任务更有效的特征组合，进一步提升模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 有些符号表示的数据特征已经相对结构化，并且以字典这种数据结构进行存储。这时我们使用DictVectorizer对特征进行抽取和向量化\n",
    "# DicVectorizer对使用字典存储的数据进行特征抽取与向量化\n",
    "\n",
    "measurements = [{'city': 'Dubai', 'temperature': 33.}, {'city': 'London', 'temperature': 12.}, {'city': 'San Fransisco', 'temperature': 18.}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   0.   0.  33.]\n",
      " [  0.   1.   0.  12.]\n",
      " [  0.   0.   1.  18.]]\n",
      "['city=Dubai', 'city=London', 'city=San Fransisco', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "\n",
    "# 输出转化后的特征矩阵\n",
    "print(vec.fit_transform(measurements).toarray())\n",
    "# 输出各个维度的特征含义\n",
    "print(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
     ]
    }
   ],
   "source": [
    "# CounterVectorizer对于每条训练文本，CounterVectorizer只考虑每种词汇在该条训练文本中出现的频率\n",
    "# 使用CounterVectorizer并且不去掉停用词的条件下，对文本特征进行量化的朴素贝叶斯分类性能测试\n",
    "from sklearn.datasets import fetch_20newsgroups  # 导入20类新闻文本数据抓取器\n",
    "# 从互联网上即时下载新闻样本，subset='all' 参数代表下载全部近2万条文本存储在变量news中\n",
    "news = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集\n",
    "from sklearn.model_selection import train_test_split  # train_test_split的新位置\n",
    "x_train, x_test, y_train, y_test = train_test_split(news.data, news.target, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 采用默认配置对CountVectorizer进行初始化（默认配置不去除英文停用词），并赋值给变量count_vec\n",
    "count_vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 只使用词频统计的方式将原始训练和测试文本转化为特征向量\n",
    "x_count_train = count_vec.fit_transform(x_train)\n",
    "x_count_test = count_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: scotts@math.orst.edu (Scott Settlemier)\n",
      "Subject: FORSALE: MAG Innovision MX15F 1280x1024\n",
      "Article-I.D.: gaia.1r7hir$9sk\n",
      "Distribution: world\n",
      "Organization: Oregon State University Math Department\n",
      "Lines: 7\n",
      "NNTP-Posting-Host: math.orst.edu\n",
      "\n",
      "MAG Innovision MX15F\n",
      "Fantastic 15\" multiscan monitor that can display up to\n",
      "1280x1024 noninterlaced (!) with .26 mm dot pitch.\n",
      "If you are looking for a large crystal clear super vga\n",
      "monitor then this is for you.\n",
      "$430   call Scott at (503) 757-3483 or\n",
      "email scotts@math.orst.edu\n",
      "\n",
      "----------------\n",
      "  (0, 60066)\t1\n",
      "  (0, 104942)\t1\n",
      "  (0, 14433)\t1\n",
      "  (0, 22750)\t1\n",
      "  (0, 17937)\t1\n",
      "  (0, 35665)\t1\n",
      "  (0, 44232)\t1\n",
      "  (0, 16311)\t1\n",
      "  (0, 79874)\t1\n",
      "  (0, 132903)\t1\n",
      "  (0, 132665)\t1\n",
      "  (0, 140565)\t1\n",
      "  (0, 129553)\t1\n",
      "  (0, 47467)\t1\n",
      "  (0, 51298)\t1\n",
      "  (0, 87060)\t1\n",
      "  (0, 65719)\t2\n",
      "  (0, 89395)\t1\n",
      "  (0, 34760)\t1\n",
      "  (0, 148646)\t2\n",
      "  (0, 76791)\t1\n",
      "  (0, 109290)\t1\n",
      "  (0, 57011)\t1\n",
      "  (0, 96571)\t1\n",
      "  (0, 11905)\t1\n",
      "  :\t:\n",
      "  (0, 88624)\t1\n",
      "  (0, 54291)\t1\n",
      "  (0, 137926)\t1\n",
      "  (0, 127872)\t1\n",
      "  (0, 105052)\t1\n",
      "  (0, 105079)\t1\n",
      "  (0, 144786)\t1\n",
      "  (0, 56181)\t1\n",
      "  (0, 27541)\t1\n",
      "  (0, 9352)\t1\n",
      "  (0, 67665)\t1\n",
      "  (0, 35136)\t1\n",
      "  (0, 4447)\t2\n",
      "  (0, 99226)\t2\n",
      "  (0, 78632)\t2\n",
      "  (0, 91899)\t2\n",
      "  (0, 65921)\t1\n",
      "  (0, 128977)\t1\n",
      "  (0, 123300)\t1\n",
      "  (0, 122222)\t2\n",
      "  (0, 59188)\t3\n",
      "  (0, 105230)\t3\n",
      "  (0, 93010)\t4\n",
      "  (0, 122236)\t2\n",
      "  (0, 66520)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print('----------------')\n",
    "print(x_count_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB  # 导入朴素贝叶斯分类器\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839770797963\n"
     ]
    }
   ],
   "source": [
    "# 得分\n",
    "print(mnb.score(x_count_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.86      0.86       201\n",
      "           comp.graphics       0.59      0.86      0.70       250\n",
      " comp.os.ms-windows.misc       0.89      0.10      0.17       248\n",
      "comp.sys.ibm.pc.hardware       0.60      0.88      0.72       240\n",
      "   comp.sys.mac.hardware       0.93      0.78      0.85       242\n",
      "          comp.windows.x       0.82      0.84      0.83       263\n",
      "            misc.forsale       0.91      0.70      0.79       257\n",
      "               rec.autos       0.89      0.89      0.89       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.98      0.91      0.95       251\n",
      "        rec.sport.hockey       0.93      0.99      0.96       233\n",
      "               sci.crypt       0.86      0.98      0.91       238\n",
      "         sci.electronics       0.85      0.88      0.86       249\n",
      "                 sci.med       0.92      0.94      0.93       245\n",
      "               sci.space       0.89      0.96      0.92       221\n",
      "  soc.religion.christian       0.78      0.96      0.86       232\n",
      "      talk.politics.guns       0.88      0.96      0.92       251\n",
      "   talk.politics.mideast       0.90      0.98      0.94       231\n",
      "      talk.politics.misc       0.79      0.89      0.84       188\n",
      "      talk.religion.misc       0.93      0.44      0.60       158\n",
      "\n",
      "             avg / total       0.86      0.84      0.82      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 其它性能指标\n",
    "from sklearn.metrics import classification_report\n",
    "y_predict = mnb.predict(x_count_test)\n",
    "print(classification_report(y_test, y_predict, target_names=news.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846349745331\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.84      0.67      0.75       201\n",
      "           comp.graphics       0.85      0.74      0.79       250\n",
      " comp.os.ms-windows.misc       0.82      0.85      0.83       248\n",
      "comp.sys.ibm.pc.hardware       0.76      0.88      0.82       240\n",
      "   comp.sys.mac.hardware       0.94      0.84      0.89       242\n",
      "          comp.windows.x       0.96      0.84      0.89       263\n",
      "            misc.forsale       0.93      0.69      0.79       257\n",
      "               rec.autos       0.84      0.92      0.88       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.96      0.91      0.94       251\n",
      "        rec.sport.hockey       0.88      0.99      0.93       233\n",
      "               sci.crypt       0.73      0.98      0.83       238\n",
      "         sci.electronics       0.91      0.83      0.87       249\n",
      "                 sci.med       0.97      0.92      0.95       245\n",
      "               sci.space       0.89      0.96      0.93       221\n",
      "  soc.religion.christian       0.51      0.97      0.67       232\n",
      "      talk.politics.guns       0.83      0.96      0.89       251\n",
      "   talk.politics.mideast       0.92      0.97      0.95       231\n",
      "      talk.politics.misc       0.98      0.62      0.76       188\n",
      "      talk.religion.misc       0.93      0.16      0.28       158\n",
      "\n",
      "             avg / total       0.87      0.85      0.84      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer 除了考量某个词在当前文本中出现的频率之外，同时关注包含这个词汇的文本条数的倒数，相比之下，训练文本的条目越多，这种特征量化方式就更有优势。\n",
    "# 因为我们计算词频的目的在于找出对所在文本的含义更有贡献的重要词汇。\n",
    "# 使用TfidfVectorizer并且不去掉停用词的条件下，对文本特征进行量化的朴素贝叶斯分类性能测试\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "x_tfidf_trian = tfidf_vec.fit_transform(x_train)\n",
    "x_tfidf_test = tfidf_vec.transform(x_test)\n",
    "\n",
    "mnb_tfidf = MultinomialNB()\n",
    "mnb_tfidf.fit(x_tfidf_trian, y_train)\n",
    "\n",
    "print(mnb_tfidf.score(x_tfidf_test, y_test))\n",
    "\n",
    "y_predict = mnb_tfidf.predict(x_tfidf_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predict, target_names=news.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述实验表明，在训练文本量较多的时候，利用TfidfVectorizer压制这些常用词汇对分类决策的干扰，往往可以起到提升模型性能的作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的实验会验证：在文本特征提取中以黑名单的方式过滤掉停用词，可以用来提高模型的性能表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863752122241\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.85      0.89      0.87       201\n",
      "           comp.graphics       0.62      0.88      0.73       250\n",
      " comp.os.ms-windows.misc       0.93      0.22      0.36       248\n",
      "comp.sys.ibm.pc.hardware       0.62      0.88      0.73       240\n",
      "   comp.sys.mac.hardware       0.93      0.85      0.89       242\n",
      "          comp.windows.x       0.82      0.85      0.84       263\n",
      "            misc.forsale       0.90      0.79      0.84       257\n",
      "               rec.autos       0.91      0.91      0.91       238\n",
      "         rec.motorcycles       0.98      0.94      0.96       276\n",
      "      rec.sport.baseball       0.98      0.92      0.95       251\n",
      "        rec.sport.hockey       0.92      0.99      0.95       233\n",
      "               sci.crypt       0.91      0.97      0.93       238\n",
      "         sci.electronics       0.87      0.89      0.88       249\n",
      "                 sci.med       0.94      0.95      0.95       245\n",
      "               sci.space       0.91      0.96      0.93       221\n",
      "  soc.religion.christian       0.87      0.94      0.90       232\n",
      "      talk.politics.guns       0.89      0.96      0.93       251\n",
      "   talk.politics.mideast       0.95      0.98      0.97       231\n",
      "      talk.politics.misc       0.84      0.90      0.87       188\n",
      "      talk.religion.misc       0.91      0.53      0.67       158\n",
      "\n",
      "             avg / total       0.88      0.86      0.85      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_filter_vec = CountVectorizer(analyzer='word', stop_words='english')\n",
    "tfidf_filter_vec = TfidfVectorizer(analyzer='word', stop_words='english')\n",
    "\n",
    "x_count_filter_train = count_filter_vec.fit_transform(x_train)\n",
    "x_count_filter_test = count_filter_vec.transform(x_test)\n",
    "\n",
    "x_tfidf_filter_train = tfidf_filter_vec.fit_transform(x_train)\n",
    "x_tfidf_filter_test = tfidf_filter_vec.transform(x_test)\n",
    "\n",
    "mnb_count_filter = MultinomialNB()\n",
    "mnb_count_filter.fit(x_count_filter_train, y_train)\n",
    "print(mnb_count_filter.score(x_count_filter_test, y_test))\n",
    "print(classification_report(y_test, mnb_count_filter.predict(x_count_filter_test), target_names=news.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882640067912\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.81      0.83       201\n",
      "           comp.graphics       0.85      0.81      0.83       250\n",
      " comp.os.ms-windows.misc       0.84      0.87      0.86       248\n",
      "comp.sys.ibm.pc.hardware       0.78      0.88      0.83       240\n",
      "   comp.sys.mac.hardware       0.92      0.90      0.91       242\n",
      "          comp.windows.x       0.95      0.88      0.91       263\n",
      "            misc.forsale       0.90      0.80      0.85       257\n",
      "               rec.autos       0.89      0.92      0.90       238\n",
      "         rec.motorcycles       0.98      0.94      0.96       276\n",
      "      rec.sport.baseball       0.97      0.93      0.95       251\n",
      "        rec.sport.hockey       0.88      0.99      0.93       233\n",
      "               sci.crypt       0.85      0.98      0.91       238\n",
      "         sci.electronics       0.93      0.86      0.89       249\n",
      "                 sci.med       0.96      0.93      0.95       245\n",
      "               sci.space       0.90      0.97      0.93       221\n",
      "  soc.religion.christian       0.70      0.96      0.81       232\n",
      "      talk.politics.guns       0.84      0.98      0.90       251\n",
      "   talk.politics.mideast       0.92      0.99      0.95       231\n",
      "      talk.politics.misc       0.97      0.74      0.84       188\n",
      "      talk.religion.misc       0.96      0.29      0.45       158\n",
      "\n",
      "             avg / total       0.89      0.88      0.88      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_tfidf_filter = MultinomialNB()\n",
    "mnb_tfidf_filter.fit(x_tfidf_filter_train, y_train)\n",
    "print(mnb_tfidf_filter.score(x_tfidf_filter_test, y_test))\n",
    "print(classification_report(y_test, mnb_tfidf_filter.predict(x_tfidf_filter_test), target_names=news.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验证明TfidfVectorizerd的特征抽取和量化方法更加具备优势；以及对停用词过滤的文本特征抽取方法，平均比不过滤停用词的模型综合性能要高出3%~4%。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
